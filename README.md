# RAG系统 - 检索增强生成

基于DeepSeek模型的RAG（检索增强生成）系统，支持文档存储、向量检索和增强生成。
#test1111
## 功能特性

- ✅ **多数据库管理**：支持创建、选择、删除多个数据库
- ✅ **Web可视化界面**：现代化的Web界面，支持文档管理和聊天交互
- ✅ **文档处理**：支持文本文件上传和自动分块
- ✅ **向量存储**：使用ChromaDB存储文档向量，支持持久化
- ✅ **嵌入模型**：支持DeepSeek嵌入模型（通过Ollama）或本地BGE模型
- ✅ **检索增强**：基于向量相似度检索相关文档
- ✅ **对话生成**：使用DeepSeek模型生成增强回答
- ✅ **对话历史**：支持多轮对话上下文
- ✅ **实时交互**：Web界面支持实时聊天和文档管理

## 安装依赖

```bash
pip install -r requirements.txt
```

**注意**：系统现在支持多种文件格式，包括：
- PDF文件处理需要 `pdfplumber` 或 `pypdf`
- Word文件处理需要 `python-docx`
- Excel文件处理需要 `pandas`、`openpyxl` 和 `xlrd`

这些库已经包含在 `requirements.txt` 中，安装依赖时会自动安装。

## 使用前准备

1. **确保Ollama服务运行**
   - 确保已部署DeepSeek模型（deepseek-r1:8b）
   - Ollama服务运行在 `http://localhost:11434`

2. **（可选）安装DeepSeek嵌入模型**
   ```bash
   ollama pull deepseek-embedding
   ```
   如果Ollama不支持deepseek-embedding，系统会自动使用本地BGE模型。

## 使用方法

### 方式一：Web界面（推荐）

1. **启动Web服务器**
   ```bash
   python start_web.py
   ```
   或者：
   ```bash
   python api.py
   ```

2. **打开浏览器**
   - 访问 `http://localhost:8000`
   - 您将看到一个现代化的Web界面

3. **使用Web界面**
   - **创建数据库**：点击"创建数据库"按钮，输入数据库名称
   - **选择数据库**：在数据库列表中选择要使用的数据库，或在聊天区域的下拉菜单中选择
   - **上传文档**：点击"上传文件"按钮，选择文本文件上传
   - **添加文本**：点击"添加文本"按钮，直接输入文本内容
   - **开始对话**：选择数据库后，在聊天区域输入问题，系统会自动检索相关文档并生成回答

### 方式二：命令行界面

```bash
python main.py
```

#### 操作选项

1. **添加文本文件到数据库**
   - 选择选项1
   - 输入文本文件路径
   - 系统会自动加载、分块和向量化文档

2. **添加文本内容到数据库**
   - 选择选项2
   - 输入文本内容（输入'END'结束）
   - 系统会自动处理并添加到数据库

3. **查询（RAG模式）**
   - 选择选项3
   - 输入您的问题
   - 系统会检索相关文档并生成增强回答

4. **查看数据库信息**
   - 选择选项4
   - 查看当前数据库中的文档数量

5. **退出**
   - 选择选项5退出系统

## 系统架构

```
RAG系统
├── document_processor.py  # 文档处理模块（加载、分块）
├── embedding_model.py     # 嵌入模型模块（向量化）
├── vector_store.py        # 向量数据库模块（ChromaDB）
├── database_manager.py    # 数据库管理模块（多数据库支持）
├── rag_system.py          # RAG系统主模块（整合所有功能）
├── rag_manager.py         # RAG管理器（多数据库RAG系统）
├── api.py                 # FastAPI后端接口
├── main.py                # 命令行主程序入口
├── start_web.py           # Web服务器启动脚本
├── templates/             # HTML模板
│   └── index.html         # 前端页面
└── static/                # 静态文件
    ├── css/
    │   └── style.css      # 样式文件
    └── js/
        └── app.js         # 前端JavaScript
```

## 工作流程

1. **文档处理**：加载文档 → 文本分块 → 提取元数据
2. **向量化**：将文本块转换为向量 → 存储到向量数据库
3. **检索**：用户查询 → 向量化查询 → 相似度检索 → 返回相关文档
4. **生成**：相关文档作为上下文 → 构建提示词 → 调用模型生成回答

## 配置说明

在 `main.py` 中可以修改以下配置：

- `ollama_url`: Ollama服务地址（默认：http://localhost:11434）
- `chat_model`: 聊天模型名称（默认：deepseek-r1:8b）
- `collection_name`: 向量数据库集合名称（默认：rag_documents）
- `chunk_size`: 文本块大小（默认：500）
- `chunk_overlap`: 文本块重叠大小（默认：50）

## 注意事项

1. 首次运行时会自动下载BGE嵌入模型（如果Ollama不支持embedding API）
2. 向量数据库会持久化存储在 `./chroma_db` 目录
3. 对话历史会保留最近20轮对话
4. 确保Ollama服务正常运行且模型已部署

## 故障排除

1. **嵌入模型加载失败**
   - 检查网络连接（首次使用需要下载模型）
   - 尝试使用Ollama的embedding API

2. **Ollama连接失败**
   - 检查Ollama服务是否运行：`ollama serve`
   - 检查模型是否已部署：`ollama list`

3. **文档处理失败**
   - **文本文件**：确保文件编码为UTF-8或GBK
   - **PDF文件**：确保PDF文件可以正常打开，且包含可提取的文本（非扫描版图片）
   - **Word文件**：仅支持.docx格式，不支持旧的.doc格式
   - **Excel文件**：确保文件格式正确，且可以正常打开
   - 检查文件路径是否正确
   - 如果缺少处理库，请重新安装依赖：`pip install -r requirements.txt`

## Web界面功能说明

### 数据库管理
- **创建数据库**：点击侧边栏的"创建数据库"按钮，输入数据库名称即可创建
- **选择数据库**：在数据库列表中点击"选择"按钮，或在下拉菜单中选择
- **删除数据库**：点击数据库列表中的"删除"按钮（需确认）

### 文档管理
- **上传文件**：点击"上传文件"按钮，支持多种文件格式：
  - 文本文件 (.txt) - 支持UTF-8、GBK等编码
  - PDF文件 (.pdf) - 自动提取文本内容
  - Word文档 (.docx) - 提取段落和表格内容
  - Excel文件 (.xlsx, .xls) - 提取所有工作表数据
- **添加文本**：点击"添加文本"按钮，直接输入文本内容
- **查看信息**：侧边栏显示当前数据库的文档数量

### 聊天交互
- **选择数据库**：在聊天区域的下拉菜单中选择要查询的数据库
- **输入问题**：在输入框中输入问题，按Enter或点击"发送"按钮
- **查看回答**：系统会显示生成的回答和参考的文档片段
- **对话历史**：系统会自动保存对话历史，支持多轮对话

## 示例

### Web界面使用
1. 启动服务器：`python start_web.py`
2. 打开浏览器：访问 `http://localhost:8000`
3. 创建数据库：点击"创建数据库"，输入名称如"知识库1"
4. 上传文档：点击"上传文件"，选择`example.txt`
5. 开始对话：在聊天区域输入问题，如"什么是RAG？"

### 命令行使用

#### 添加文档
```
请选择操作 (1-5): 1
请输入文件路径: example.txt
正在处理文档...
成功添加 10 个文档到向量数据库
文档添加成功！
```

#### 查询
```
请选择操作 (1-5): 3
请输入您的问题: 什么是RAG？

正在检索相关文档...
检索到的相关文档:
[文档 1]
来源: example.txt
相似度: 0.8542
内容预览: RAG（检索增强生成）是一种...

回答:
RAG（检索增强生成）是一种结合了信息检索和文本生成的技术...
```

## 许可证

MIT License

